# GPT-Vis MCP 测试套件

## 🎯 测试目标

验证GPT-Vis MCP项目的所有核心需求和功能：

1. **100%智能调用机制** - AI自动判断数据可视化需求
2. **RAG智能替代硬编码** - 使用知识库检索而非硬编码规则
3. **两个核心工具职责分离** - 判断工具 vs 创建工具
4. **完整vis-chart输出** - 标准格式的图表配置

## 📁 测试文件结构

```
test/
├── README.md                    # 测试说明文档
├── run-all-tests.js            # 统一测试运行器（主要测试）
├── quick-test.js               # 快速单元测试
└── comprehensive-test.js       # 详细集成测试
```

## 🚀 运行测试

### 1. 完整测试套件（推荐）
```bash
npm test
```

**包含所有核心功能验证：**
- 🔧 基础功能测试 - 工具列表、基础调用
- 🧠 智能判断核心测试 - 各种数据需求场景
- 🔄 最后调用工作流程测试 - 验证最终调用逻辑
- 📊 图表创建和输出测试 - vis-chart生成和复制指示
- 🔍 边界情况测试 - 空数据、复杂查询处理

### 2. 快速单元测试
```bash
npm run test:unit
```

**验证核心功能：**
- ✅ 100%智能调用测试
- ❌ 正确拒绝非数据问题
- 📊 RAG智能图表创建

### 3. 集成测试
```bash
npm run test:integration
```

**全面集成测试：**
- 完整工作流程验证
- 性能和稳定性测试
- 大数据量处理测试

## 📊 测试覆盖范围

### 智能判断测试场景

#### ✅ 应该触发可视化的场景
- "帮我统计淮安平均月收入" → 柱状图
- "我想了解用户增长趋势" → 折线图
- "显示各产品类别的市场占比" → 饼图
- "帮我对比一下各个部门的绩效表现情况" → 柱状图

#### ❌ 不应该触发可视化的场景
- "今天北京天气怎么样" → 不需要可视化
- "你好，请问现在几点了" → 不需要可视化

### 图表创建测试场景

#### 时间序列数据
```javascript
{
  data: [
    { month: "1月", sales: 120000, users: 1500 },
    { month: "2月", sales: 135000, users: 1650 }
  ]
}
```
**期望**: 智能推荐折线图

#### 分类数据
```javascript
{
  data: [
    { department: "销售部", performance: 95 },
    { department: "市场部", performance: 88 }
  ]
}
```
**期望**: 智能推荐柱状图

#### 占比数据
```javascript
{
  data: [
    { category: "移动端", count: 450 },
    { category: "PC端", count: 280 }
  ]
}
```
**期望**: 智能推荐饼图（如指定chartType: "pie"）

## 🔍 测试验证点

### 1. RAG智能特征验证
- ✅ 响应包含"智能分析"、"RAG"关键词
- ✅ 提供置信度信息（80%以上）
- ✅ 包含推荐理由说明
- ✅ 知识库加载成功

### 2. 工具职责分离验证
- ✅ `check_if_needs_visualization` 只返回判断结果
- ✅ `create_data_visualization` 专门生成图表
- ✅ 两个工具功能不重叠

### 3. 输出格式验证
- ✅ 标准vis-chart格式
- ✅ 包含type、data、xField、yField
- ✅ 正确的数据字段映射

### 4. 边界情况处理
- ✅ 空数据处理
- ✅ 单条数据处理
- ✅ 大数据量处理
- ✅ 复杂中文查询

## 📈 测试结果解读

### 成功指标
- **成功率 > 90%**: 基本功能正常
- **RAG智能特征**: 所有响应包含智能分析标识
- **置信度 > 80%**: AI判断准确性高
- **图表生成**: 所有数据都能生成有效图表

### 常见问题排查

#### 1. 知识库加载失败
```
❌ 检查knowledges/目录是否存在
❌ 检查markdown文件格式是否正确
```

#### 2. 图表生成失败
```
❌ 检查数据格式是否正确
❌ 检查RAG服务是否正常运行
```

#### 3. 智能判断不准确
```
❌ 检查RAG服务shouldVisualize方法
❌ 检查关键词检测逻辑
```

## 🎯 核心需求验证清单

- [ ] **100%调用率**: AI遇到数据问题必然调用判断工具
- [ ] **RAG智能**: 不使用硬编码关键词，通过知识库检索
- [ ] **职责分离**: 判断工具只判断，创建工具只创建
- [ ] **完整输出**: 生成标准vis-chart格式配置
- [ ] **智能推荐**: 基于数据特征推荐合适图表类型
- [ ] **错误处理**: 优雅处理各种边界情况

## 📝 测试报告

运行测试后，系统会生成详细的测试报告，包括：

- 📊 测试通过率统计
- 💡 功能验证结果
- ❌ 错误详情和排查建议
- 🎯 核心需求完成度评估

---

**让每一次测试都验证我们的智能化承诺！** 🚀 
